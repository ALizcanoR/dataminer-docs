---
uid: Comp_About_DataMiner
---

# About DataMiner

DataMiner is a standard, proven and very widely adopted and endorsed, open and fully independent software platform providing:

1. **DATA INGEST & CONTROL: powerful data ingest and control plane capabilities**, enabling operators to ingest data from any product, irrespective of the interface or the protocol required, transparently across any vendor or domain boundaries, covering both hardware products, software products and cloud services.  With DataMiner in place, users have the unconditional guarantee that they can truly ingest any data from across their entire operation, in a secure, scalable, and fully standardized way.  And because of the open architecture, anybody can design, build, and deploy new connectors for that purpose, fully supporting devops operations.  

    This part of the DataMiner System is all about **creating a fully standardized and real-time updated digital twin of the entire underlying operation**, which is a very unique proposition and key differentiator compared to the proliferation of general-purpose data collection solutions.  In that sense, DataMiner really stands for a class of its own, providing out of the box what would be otherwise a complex, cumbersome and expensive mash-up of disparate software components.

1. **DATA PROCESSING & WORKFLOW: advanced out of the box and fully standardized open architecture data processing** (e.g. standard advanced fault & performance management, AI-based data processing and analytics, data-aggregation, industry standard big data storage, uniform real-time service modelling and management, and much more) **as well as - again out of the box and standardized - sophisticated end to end workflow automation capabilities** (e.g. standard orchestration, unified resource management, transparent process automation and much more), **which all leverage out of the box integrations with the aforementioned standard digital twin of the operation**, resulting in fast, efficient and continuous deployment of solutions.  The latter irrespective of new products and data sources to be connected in the future, resulting in a very future-proof solution and considerable savings.

1. **DATA CONSUMPTION & CONTROL SURFACE**: fully standardized out of the box and open architecture data consumption and control surface tooling (e.g. standard graphical bubble-up and drill down UIs, control surfaces such as data display and button control panels, signal routing UIs, KPI dashboards, RF spectrum UIs, no-code user-definable APPs, and much more) as well as powerful standardized professionally secured and scalable APIs enabling the plug-in of any other 3rd party data consumption or control APPs.   Again, all leveraging the underlying standardized digital twin of the operation, enabling fast and continuous integration of the end-to-end operation.

This is visualized in the architecture drawing below:

![Architecture](~/compendium/images/DataMiner_architecture.png)

The pronounced open architecture of DataMiner enables anybody, including Skyline, the user himself as well as any 3rd party system integrators and ICT contractors, to design powerful end to end solutions.  And this in a continuous fashion, enabling a devops style of operation and business.  This including connecting the DataMiner platform with new data sources and products on the fly, creating and deploying new data processing routines and logic, as well as designing and operating data consumption and control surfaces for the users.

In that sense, the DataMiner platform can be compared to a Microsoft O365, SAP or Salesforce platform, providing a full-featured and out of the box highly integrated standardized and proven ecosystem, where users can easily plug in their data sources and any 3rd party products they rely on for their operation, and focus on creating a unified, secure, scalable, and standardized open environment to consume and leverage their operational data, to manage and orchestrate their services end to end, along with automation of their end to end technical, operational and business workflows.  And in addition to that provide easy, secure and scalable access to fully standardized data for all types of consumers, both through standard included DataMiner applications or third-party data consumption products and apps.

DataMiner focuses on providing a highly standardized and fully out of the box experience when it comes to data ingest, processing, flow and utilization, while providing the users complete freedom to focus their time and efforts on tailoring it and evolving it devops-style in line with their specific operational and business needs (e.g. ingesting data from their specific products, modelling their specific services, crafting their specific UIs and control surfaces, creating their unique workflows etc.).   And this is key essential to success, because each operation and environment is unique, and excellence can only be achieved if there is sufficient flexibility in the tooling that is leveraged.

DataMiner, for that purpose, creates a fully standardized digital twin of the operation, that runs transparently across any vendor, technology or domain boundaries of an operation.  The digital twin provides a real-time and fully standardized representation of all managed assets, irrespective whether thatâ€™s hardware, software or cloud services, along with powerful standard modelling of all relationships, such as physical and logical connectivity, dependencies and much more. And all standard DataMiner platform capabilities come fully integrated with those digital twin objects, enabling those to tap into the data of the digital twin objects or to control those objects out of the box, independent of the underlying technology or interfaces.  

![Instant integration of managed objects](~/compendium/images/instant_integration_of_managed_object.png)

DataMiner also provides the choice to be deployed as a platform on-premises or in a private or public cloud, or in a hybrid fashion.
